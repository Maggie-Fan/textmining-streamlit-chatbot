import streamlit as st
import autogen
from autogen import ConversableAgent, LLMConfig
from autogen import AssistantAgent, UserProxyAgent
from autogen.code_utils import content_str # for OpenAI
import ast
import traceback
from tools.esg_tool_register import register_one_agent_all_tools # register_all_tools


GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", None)

if GEMINI_API_KEY is None:
    raise RuntimeError("GEMINI_API_KEY not found in secrets.toml")

def get_agent_persona():
    pdf_content = st.session_state.get("pdf_text", "")
    lang_setting = st.session_state.get("lang_setting", "English")

    if pdf_content:
        tool_usage_guide = """
        The user has uploaded a PDF report. You may use the following commands to help them explore it:

        - show_pdf_content â†’ Display the full PDF text from the uploaded ESG report.
        - show_pdf_page_content(n) â†’ Show content from a specific page in the uploaded ESG report `n` (e.g., show_pdf_page_content(2)).
        - esg_analysis â†’ Extract ESG insights from the PDF.
        """
    else:
        tool_usage_guide = "User didnt upload ESG report; please gently remind users to upload one ESG report."

    agent_persona = f"""
        You are an ESG analysis assistant. Your role is to help users understand, interpret, and analyze ESG (Environmental, Social, Governance) reports and related topics.

        Before answering, first check if the userâ€™s message is meaningfully related to ESG concepts, sustainability reporting, or corporate responsibility.

        If the userâ€™s message is not relevant to ESG or sustainability, **do not** answer the question directly. Instead, gently remind the user to keep the conversation focused on ESG-related topics.

        {tool_usage_guide}

        Please generate your response below:
        - If the user message clearly maps to a tool (e.g., showing PDF content or performing ESG analysis), use that tool directly.
        - Do not ask the user to choose.

        1. Fallback & Termination
        â€“ On successful completion or when ending or after using the `tool`, return '##ALL DONE##'.
        - Return '##ALL DONE##' and respond accordingly when:
            â€¢ The task is completed.
            â€¢ The input is empty.
            â€¢ An error occurs.
            â€¢ The request is repeated.
            â€¢ Additional confirmation is required from the user.
        2. Please output in {lang_setting}
        """

    return agent_persona

gemini_config = LLMConfig(
    api_type = "google",
    model="gemini-2.0-flash-lite", # The specific model
    api_key=GEMINI_API_KEY, # Authentication
)

gemini_agent = ConversableAgent(
    name="Gemini",
    llm_config=gemini_config,
    # max_consecutive_auto_reply=1, # user cannot interact with terminal if set max_consecutive_auto_reply
    system_message=get_agent_persona()
)
# register_all_tools(gemini_agent)

# assistant = AssistantAgent(
#     "assistant",
#     llm_config=gemini_config,
#     max_consecutive_auto_reply=3
# )

def is_terminated_custom(x):
    try:
        print("ğŸ” Received message x:", x)  # << åŠ åœ¨é€™è£¡ debug çœ‹æ•´å€‹ message æ ¼å¼

        # tool call é‚„æ²’åŸ·è¡Œå®Œï¼Œä¸èƒ½çµ‚æ­¢
        if "tool_calls" in x:
            return False

        content = x.get("content", "")
        if isinstance(content, dict):
            content = content.get("output", "")
        elif isinstance(content, list):
            content = " ".join([
                str(c.get("content", "")) if isinstance(c, dict) else str(c)
                for c in content
            ])
        print("ğŸ§ª Parsed content:", content)  # << çœ‹å¯¦éš›æŠ“åˆ°çš„å…§å®¹

        return "##ALL DONE##" in content
    except Exception as e:
        print("âŒ Error in termination check:", e)
        return False

user_proxy = UserProxyAgent(
    "user_proxy",
    human_input_mode="NEVER", # "TERMINATE"
    code_execution_config=False,
    # is_termination_msg=lambda x: content_str(x.get("content")).find("##ALL DONE##") >= 0, # for OpenAI
    is_termination_msg=is_terminated_custom
)
register_one_agent_all_tools(agent=gemini_agent, proxy=user_proxy)

def chat_with_gemini(prompt: str, restrict = True) -> str:
    lang_setting = st.session_state.get("lang_setting", "")

    if restrict:
        prompt_template = f"""
        You are an ESG analysis assistant. Your role is to help users understand, interpret, and analyze ESG (Environmental, Social, Governance) reports and related topics.

        Before answering, first check if the userâ€™s message is meaningfully related to ESG concepts, sustainability reporting, or corporate responsibility.

        If the userâ€™s message is not relevant to ESG or sustainability, **do not** answer the question directly. Instead, gently remind the user to keep the conversation focused on ESG-related topics.

        Here is the user message:
        \"\"\"{prompt}\"\"\"

        Please output in {lang_setting}
        Please generate your response below:
        """
    else:
        prompt_template = prompt

    try:
        message = {"role": "user", "content": prompt_template}
        temp_gemini_agent = ConversableAgent(
            name="Gemini",
            llm_config=gemini_config
        )
        reply = temp_gemini_agent.generate_reply(messages=[message])

        if not reply or "content" not in reply:
            return "âš ï¸ Gemini did not return a valid reply."

        return content_str(reply["content"])
    except Exception as e:
        tb = traceback.format_exc()
        return f"âš ï¸ Gemini error: {type(e).__name__} - {e}\n\n{tb}"

# Extract chat history or tool response from Gemini Assitant output
def extract_final_response(chat_history, tag: str = "##ALL DONE##") -> str:
    """
    å¾ AutoGen chat history ä¸­æå–å«æœ‰æŒ‡å®šçµ‚æ­¢æ¨™è¨˜çš„å›æ‡‰ï¼Œæˆ–åœ¨åµæ¸¬åˆ° tool call æ™‚åˆä½µå…¶å¾Œå…©å‰‡å›æ‡‰ã€‚

    Args:
        chat_history (List[Dict]): AutoGen å°è©±æ­·å²
        tag (str): çµ‚æ­¢æ¨™è¨˜å­—ä¸²ï¼ˆé è¨­ç‚º '##ALL DONE##'ï¼‰

    Returns:
        str: ç§»é™¤çµ‚æ­¢æ¨™è¨˜å¾Œçš„å…§å®¹ï¼Œæˆ–åˆä½µå·¥å…·å¾Œå…©å¥è©±çš„å…§å®¹ã€‚å¦‚ç„¡å‰‡å›å‚³ fallbackã€‚
    """

    chat_history = chat_history[1:]  # Skip user prompt

    def extract_output(msg):
        """å¾ä¸€å‰‡è¨Šæ¯ä¸­æå– output å­—ä¸²"""
        if isinstance(msg, dict):
            content = msg.get("content", "")
            if isinstance(content, dict):
                return content.get("output", "")
            elif isinstance(content, str):
                # å˜—è©¦è§£æå­—ä¸²ç‚º dict
                try:
                    parsed = ast.literal_eval(content)
                    if isinstance(parsed, dict) and "output" in parsed:
                        return parsed["output"]
                except:
                    pass
                return content  # fallback: åŸå§‹å­—ä¸²
        elif isinstance(msg, str):
            return msg
        return ""

    # å„ªå…ˆè™•ç† tool_calls + æ¥çºŒçš„å…©å‰‡è¨Šæ¯åˆä½µ
    for i, msg in enumerate(chat_history):
        if "tool_calls" in msg:
            msg1 = chat_history[i + 1] if i + 1 < len(chat_history) else {}
            msg2 = chat_history[i + 2] if i + 2 < len(chat_history) else {}
            text1 = extract_output(msg1).strip()
            text2 = extract_output(msg2).strip()
            combined = f"{text1}\n\n{text2}".strip()
            if combined:
                return combined

    # è™•ç†å« tag çš„ç´”æ–‡å­—è¨Šæ¯
    for msg in chat_history:
        if "tool_calls" in msg:
            continue
        content = msg.get("content", "")
        if isinstance(content, str) and tag in content:
            return content.replace(tag, "").strip()
        if isinstance(content, dict):
            output = content.get("output", "")
            if tag in output:
                return output.replace(tag, "").strip()

    # fallback æœ€å¾Œä¸€å‰‡æœ‰æ•ˆå…§å®¹ï¼ˆå‰ä¸€å‰‡éç©º or ç¬¬ä¸€å‰‡ï¼‰
    for i in range(len(chat_history) - 1, -1, -1):
        curr_msg = chat_history[i]
        curr_content = curr_msg.get("content", "")

        # âœ… å¦‚æœç•¶å‰è¨Šæ¯æ²’å…§å®¹ï¼Œè·³é
        if not isinstance(curr_content, (str, dict)) or not str(curr_content).strip():
            continue

        # âœ… å¦‚æœæ˜¯ç¬¬ä¸€å‰‡è¨Šæ¯ï¼Œä¸ç”¨ç®¡å‰ä¸€å‰‡ï¼Œç›´æ¥å›å‚³
        if i == 0:
            if isinstance(curr_content, dict) and "output" in curr_content:
                return curr_content["output"]
            return str(curr_content).strip()

        # âœ… æª¢æŸ¥å‰ä¸€å‰‡å…§å®¹
        prev_msg = chat_history[i - 1]
        prev_content = prev_msg.get("content", "")

        # ğŸš« åªæœ‰ã€Œå‰ä¸€å‰‡æ˜¯ç©º & æ˜¯ user_proxyã€æ™‚æ‰ continue
        if (
            isinstance(prev_content, str) and not prev_content.strip()
            and prev_msg.get("role") == "assistant" and prev_msg.get("name") == "user_proxy"
        ):
            continue  # âŒ å…¶ä»–ç©ºè¨Šæ¯ä¹Ÿä¸æ¡ç”¨ï¼Œå¾€å‰æ‰¾

        # âœ… å¦å‰‡ï¼Œç•¶å‰è¨Šæ¯å¯è¢«æ¥å—ç‚º fallback
        if isinstance(curr_content, dict) and "output" in curr_content:
            return curr_content["output"]
        return str(curr_content).strip()

    # è‹¥å…¨éƒ¨éƒ½ä¸ç¬¦åˆï¼Œå›å‚³é è¨­è¨Šæ¯
    return "âš ï¸ No valid response found."

# Use agent (gemini) with registered tools
def chat_with_gemini_agent(prompt: str, restrict = True) -> str:
    pdf_content = st.session_state.get("pdf_text", "")
    lang_setting = st.session_state.get("lang_setting", "English")

    if pdf_content:
        tool_usage_guide = """
        If the user asks about the uploaded ESG report (or clearly refers to its contents), you may use the following functions:

        - show_pdf_content â†’ Display the full PDF text from the uploaded ESG report.
        - show_pdf_page_content(n) â†’ Show content from a specific page in the uploaded ESG report `n` (e.g., show_pdf_page_content(2)).
        - esg_analysis â†’ Extract ESG insights from the PDF.
        """
        # - clustering analysis â†’ Run clustering analysis on the PDF.
    else:
        tool_usage_guide = "User didnt upload ESG report; please gently remind users to upload one ESG report."

    if restrict:
        prompt_template = f"""
        You are an ESG assistant. You may help the user by answering general ESG-related questions directly.

        {tool_usage_guide}

        Here is the user message:
        \"\"\"{prompt}\"\"\"

        Please generate your response below:
        - If the user message clearly maps to a tool (e.g., showing PDF content or ESG analysis), use that tool directly.
        - Do not ask the user to choose.
        - After using the `tool`, return '##ALL DONE##'

        1. Fallback & Termination
        â€“ On successful completion or when ending, return '##ALL DONE##'.
        - Return '##ALL DONE##' and respond accordingly when:
            â€¢ The task is completed.
            â€¢ The input is empty.
            â€¢ An error occurs.
            â€¢ The request is repeated.
            â€¢ Additional confirmation is required from the user.
        2. Please output in {lang_setting}
        """
    else:
        prompt_template = prompt

    try:
        result = user_proxy.initiate_chat(
            recipient=gemini_agent,
            message=prompt_template,
            max_turns=2 # User cannot interact with terminal (user_proxy (to Gemini) will be empty in further turns) if set max_turns
        )

        chat_history = result.chat_history
        print(chat_history)
        response = extract_final_response(chat_history)
        if "##ALL DONE##" in response:
            response = response.replace("##ALL DONE##", "").rstrip().rstrip("\n")
        return response

    except Exception as e:
        tb = traceback.format_exc()
        return f"âš ï¸ Gemini error: {type(e).__name__} - {e}\n\n{tb}"

